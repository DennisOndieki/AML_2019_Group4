# AML_2019_Group4

## Gradient Descent Implementation in Python
</p>Gradient descent is one of the key useful tools in machine learning.
</p>In machine learning, gradient descent is very important when optimizing functions.
</p>It is employed to determine the best parameters to fit in a model to reduce the prediction error
</p>
## Gradient Descent: The Six-Hump Camel Function
</p>The six-hump camel function is one of the optimization test problems used to demonstrate machine learning.
</p>The recommended evaluation range of the function is x ∈ [-3, 3] and y ∈ [-2, 2].
</p>The function has six local minima of which two are the global minima.
</p>The global minima of the function lie at (x, y) = (0.0898, -0.7126) and (-0.0898, 0.7126) 
</p>The images below show the six-hump camel function:
<p align="center">
  <img src="https://github.com/DennisOndieki/AML_2019_Group4/blob/master/Images/6_hump_plot.png" width="425"> <img src="https://github.com/DennisOndieki/AML_2019_Group4/blob/master/Images/6_hump_closeup.png" width="425">
</p>
## Note: Key Functions for Analysis:
</p>
<p align="center">
  <img src="https://github.com/DennisOndieki/AML_2019_Group4/blob/master/Images/loss_function.png" width="425"> 
</p>
<p align="center">
  <img src="https://github.com/DennisOndieki/AML_2019_Group4/blob/master/Images/partial_x.png" width="425"> <img src="https://github.com/DennisOndieki/AML_2019_Group4/blob/master/Images/partial_y.png" width="425">
</p>
</p>
</p>
